{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queue & Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "[40]\n"
     ]
    }
   ],
   "source": [
    "class Queue:\n",
    "  def __init__(self):\n",
    "    self.data = []\n",
    "\n",
    "  def is_empty(self):\n",
    "    return len(self.data) == 0\n",
    "\n",
    "  def enqueue(self, value):\n",
    "    self.data.append(value)\n",
    "\n",
    "  def dequeue(self):\n",
    "    return self.data.pop(0)\n",
    "\n",
    "  def __str__(self):\n",
    "    return str(self.data)\n",
    "\n",
    "\n",
    "queue = Queue()\n",
    "queue.enqueue(10)\n",
    "queue.enqueue(20)\n",
    "queue.enqueue(30)\n",
    "\n",
    "print(queue.dequeue())\n",
    "print(queue.dequeue())\n",
    "queue.enqueue(40)\n",
    "print(queue.dequeue())\n",
    "print(queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "20\n",
      "40\n",
      "[10]\n"
     ]
    }
   ],
   "source": [
    "class Stack:\n",
    "  def __init__(self):\n",
    "    self.data = []\n",
    "\n",
    "  def is_empty(self):\n",
    "    return len(self.data) == 0\n",
    "\n",
    "  def push(self, value):\n",
    "    self.data.append(value)\n",
    "\n",
    "  def pop(self):\n",
    "    return self.data.pop()\n",
    "\n",
    "  def __str__(self):\n",
    "    return str(self.data)\n",
    "\n",
    "\n",
    "stack = Stack()\n",
    "stack.push(10)\n",
    "stack.push(20)\n",
    "stack.push(30)\n",
    "\n",
    "print(stack.pop())\n",
    "print(stack.pop())\n",
    "stack.push(40)\n",
    "print(stack.pop())\n",
    "print(stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert adjacency matrix to adjacency list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [1, 2],\n",
       " 1: [0, 2, 3, 4, 5],\n",
       " 2: [0, 1, 3, 4, 5],\n",
       " 3: [1, 2, 4],\n",
       " 4: [1, 2, 3, 5],\n",
       " 5: [1, 2, 4, 6],\n",
       " 6: [5]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def adjacency_matrix_to_list(adjacency_matrix):\n",
    "  n = len(adjacency_matrix)\n",
    "  adjacency_list = {i: [] for i in range(n)}\n",
    "\n",
    "  for i in range(n):\n",
    "    for j in range(n):\n",
    "      if adjacency_matrix[i][j] == 1:\n",
    "        adjacency_list[i].append(j)\n",
    "  return adjacency_list\n",
    "\n",
    "\n",
    "adjacency_matrix = [[0, 1, 1, 0, 0, 0, 0],\n",
    "                    [1, 0, 1, 1, 1, 1, 0],\n",
    "                    [1, 1, 0, 1, 1, 1, 0],\n",
    "                    [0, 1, 1, 0, 1, 0, 0],\n",
    "                    [0, 1, 1, 1, 0, 1, 0],\n",
    "                    [0, 1, 1, 0, 1, 0, 1],\n",
    "                    [0, 0, 0, 0, 0, 1, 0]]\n",
    "\n",
    "adjacency_matrix_to_list(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GrPA 1\n",
    "\n",
    "### Walkthrough\n",
    "\n",
    "1. **Convert the matrix**\n",
    "   - Change the adjacency matrix into an adjacency list for easier traversal.\n",
    "\n",
    "2. **BFS**\n",
    "   - Use BFS to explore each person level by level, starting from Px.\n",
    "\n",
    "3. **Track levels**\n",
    "   - Track the number of steps (levels) it takes to reach each person from Px.\n",
    "\n",
    "4. **Return connectivity level**\n",
    "   - Return the connection level between Px and Py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_my_input(my_input):\n",
    "  data = my_input.strip().split('\\n')\n",
    "\n",
    "  n = int(data[0])\n",
    "  adjacency_matrix = [list(map(int, data[i+1].split())) for i in range(n)]\n",
    "  px = int(data[-2])\n",
    "  py = int(data[-1])\n",
    "\n",
    "  return n, adjacency_matrix, px, py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bfs(adjacency_list, start_vertex):\n",
    "  visited = {vertex: False for vertex in adjacency_list}\n",
    "  level = {vertex: 0 for vertex in adjacency_list}\n",
    "\n",
    "  queue = Queue()\n",
    "  queue.enqueue(start_vertex)\n",
    "  visited[start_vertex] = True\n",
    "\n",
    "  while not queue.is_empty():\n",
    "    curr_vertex = queue.dequeue()\n",
    "\n",
    "    for adj_vertex in adjacency_list[curr_vertex]:\n",
    "      if not visited[adj_vertex]:\n",
    "        queue.enqueue(adj_vertex)\n",
    "        visited[adj_vertex] = True\n",
    "        level[adj_vertex] = level[curr_vertex]+1\n",
    "  return level\n",
    "\n",
    "\n",
    "def find_connection_level(n, adjacency_matrix, px, py):\n",
    "  adjacency_list = adjacency_matrix_to_list(adjacency_matrix)  # helper function\n",
    "  level = bfs(adjacency_list, px)  # helper function\n",
    "  return level[py]\n",
    "\n",
    "\n",
    "find_connection_level(*parse_my_input(\"\"\"\n",
    "7\n",
    "0 1 1 0 0 0 0\n",
    "1 0 1 1 1 1 0\n",
    "1 1 0 1 1 1 0\n",
    "0 1 1 0 1 0 0\n",
    "0 1 1 1 0 1 0\n",
    "0 1 1 0 1 0 1\n",
    "0 0 0 0 0 1 0\n",
    "6\n",
    "0\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GrPA 2\n",
    "\n",
    "### Walkthrough\n",
    "\n",
    "1. **BFS**\n",
    "   - Implement BFS to explore the network starting from a given tank and mark all reachable tanks as visited.\n",
    "\n",
    "2. **Make adjacency list**\n",
    "   - Convert the list of pipes into an adjacency list for easier traversal.\n",
    "\n",
    "3. **Check each tank**\n",
    "   - For each tank, run BFS to see if all other tanks are reachable from it.\n",
    "\n",
    "4. **Return master tank**\n",
    "   - If a tank can reach all other tanks, return that tank as the master tank. If no such tank exists, return 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_my_input(my_input):\n",
    "  data = my_input.strip().split('\\n')\n",
    "\n",
    "  V = list(map(int, data[0].split()))\n",
    "  E = [list(map(int, edge.split())) for edge in data[2:]]\n",
    "\n",
    "  return V, E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bfs(adjacency_list, start_vertex):\n",
    "  visited = {vertex: False for vertex in adjacency_list}\n",
    "\n",
    "  queue = Queue()\n",
    "  queue.enqueue(start_vertex)\n",
    "  visited[start_vertex] = True\n",
    "\n",
    "  while not queue.is_empty():\n",
    "    curr_vertex = queue.dequeue()\n",
    "\n",
    "    for adj_vertex in adjacency_list[curr_vertex]:\n",
    "      if not visited[adj_vertex]:\n",
    "        queue.enqueue(adj_vertex)\n",
    "        visited[adj_vertex] = True\n",
    "  return visited\n",
    "\n",
    "\n",
    "def find_master_tank(tanks, pipes):\n",
    "  adjacency_list = {u: [] for u in tanks}\n",
    "  for u, v in pipes:\n",
    "    adjacency_list[u].append(v)\n",
    "\n",
    "  for vertex in adjacency_list:\n",
    "    visited = bfs(adjacency_list, vertex)  # helper function\n",
    "    if all(visited.values()):\n",
    "      return vertex\n",
    "  return 0\n",
    "\n",
    "\n",
    "find_master_tank(*parse_my_input(\"\"\"\n",
    "1 2 3 4\n",
    "3\n",
    "1 2\n",
    "2 3\n",
    "2 4\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GrPA 3\n",
    "\n",
    "### Walkthrough\n",
    "\n",
    "1. **DFS and Topological Sort**\n",
    "   - Perform DFS to generate a topological order of the graph using the `topological_sort` function.\n",
    "\n",
    "2. **Longest path calculation**\n",
    "   - Initialize longest path lengths to -1 and set the start node's length to 0.\n",
    "   - Maintain a predecessor dictionary to trace paths.\n",
    "\n",
    "3. **Path reconstruction**\n",
    "   - Identify the node with the maximum path length.\n",
    "   - Reconstruct the path from this node back to the start using the predecessor dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs(adjacency_list, curr_vertex, visited, stack):\n",
    "  visited[curr_vertex] = True\n",
    "\n",
    "  for neighbor in adjacency_list[curr_vertex]:\n",
    "    if not visited[neighbor]:\n",
    "      dfs(adjacency_list, neighbor, visited, stack)\n",
    "\n",
    "  stack.append(curr_vertex)\n",
    "\n",
    "\n",
    "def topological_sort(adjacency_list):\n",
    "  visited = {vertex: False for vertex in adjacency_list}\n",
    "  stack = []\n",
    "\n",
    "  for vertex in adjacency_list:\n",
    "    if not visited[vertex]:\n",
    "      dfs(adjacency_list, vertex, visited, stack)\n",
    "\n",
    "  # the stack contains the topologically sorted order in reverse\n",
    "  return stack[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_path(adjacency_list):\n",
    "  # compute topological order\n",
    "  topological_order = topological_sort(adjacency_list)\n",
    "\n",
    "  # initialize distances and predecessors\n",
    "  distances = {vertex: -1 for vertex in adjacency_list}\n",
    "  predecessor = {vertex: None for vertex in adjacency_list}\n",
    "\n",
    "  # start from the first node in topological order\n",
    "  start_vertex = topological_order[0]\n",
    "  distances[start_vertex] = 0\n",
    "\n",
    "  # compute distances, predecessor\n",
    "  for parent in topological_order:\n",
    "    if distances[parent] != -1:  # if parent has a distance assigned\n",
    "      for child in adjacency_list[parent]:\n",
    "        new_distance = distances[parent] + 1\n",
    "        if new_distance > distances[child]:\n",
    "          distances[child] = new_distance\n",
    "          predecessor[child] = parent\n",
    "\n",
    "  return distances, predecessor\n",
    "\n",
    "\n",
    "def display_path_info(distances, predecessor):\n",
    "  # display information for visualization\n",
    "  sorted_vertices = sorted(distances, key=distances.get)\n",
    "  display([(vertex, distances[vertex], predecessor[vertex]) for vertex in sorted_vertices])\n",
    "\n",
    "\n",
    "def reconstruct_path(last_vertex, predecessor):\n",
    "  # reconstruct the path from last_vertex back to start_vertex\n",
    "  path = []\n",
    "  while last_vertex is not None:\n",
    "    path.append(last_vertex)\n",
    "    last_vertex = predecessor[last_vertex]\n",
    "  path.reverse()\n",
    "  return path\n",
    "\n",
    "\n",
    "def long_journey(adjacency_list):\n",
    "  distances, predecessor = longest_path(adjacency_list)\n",
    "\n",
    "  # visualize distances and predecessors\n",
    "  display_path_info(distances, predecessor)\n",
    "\n",
    "  # reconstruct the path\n",
    "  last_vertex = max(distances, key=distances.get)\n",
    "  return reconstruct_path(last_vertex, predecessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Leh', 0, None),\n",
       " ('Shimla', 1, 'Leh'),\n",
       " ('Rishikesh', 2, 'Shimla'),\n",
       " ('Delhi', 3, 'Rishikesh'),\n",
       " ('Agra', 4, 'Delhi'),\n",
       " ('Sravasti', 4, 'Delhi'),\n",
       " ('Jaipur', 4, 'Delhi'),\n",
       " ('Pushkar', 5, 'Jaipur'),\n",
       " ('Kushinagar', 5, 'Sravasti'),\n",
       " ('Vaishali', 6, 'Kushinagar'),\n",
       " ('Udaipur', 6, 'Pushkar'),\n",
       " ('Ranthambore', 6, 'Pushkar'),\n",
       " ('Sarnath', 6, 'Kushinagar'),\n",
       " ('Varanasi', 7, 'Sarnath'),\n",
       " ('Gir', 7, 'Udaipur'),\n",
       " ('Bodhgaya', 8, 'Varanasi'),\n",
       " ('Khajuraho', 8, 'Varanasi'),\n",
       " ('Kolkatta', 9, 'Bodhgaya'),\n",
       " ('Ajanta', 10, 'Kolkatta'),\n",
       " ('Ellora', 11, 'Ajanta'),\n",
       " ('Aurangabad', 12, 'Ellora'),\n",
       " ('Mumbai', 13, 'Aurangabad'),\n",
       " ('Goa', 14, 'Mumbai'),\n",
       " ('Bangalore', 15, 'Goa'),\n",
       " ('Chennai', 16, 'Bangalore'),\n",
       " ('Madurai', 17, 'Chennai'),\n",
       " ('Cochin', 18, 'Madurai'),\n",
       " ('Thiruvanandhapuram', 19, 'Cochin'),\n",
       " ('Kanyakumari', 20, 'Thiruvanandhapuram')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjacency_list = {\n",
    "    'Madurai': ['Cochin', 'Kanyakumari'],\n",
    "    'Vaishali': [],\n",
    "    'Varanasi': ['Khajuraho', 'Bodhgaya'],\n",
    "    'Thiruvanandhapuram': ['Kanyakumari'],\n",
    "    'Udaipur': ['Gir', 'Ajanta'],\n",
    "    'Rishikesh': ['Delhi'],\n",
    "    'Shimla': ['Rishikesh'],\n",
    "    'Bangalore': ['Chennai', 'Madurai'],\n",
    "    'Agra': ['Ranthambore'],\n",
    "    'Ellora': ['Aurangabad'],\n",
    "    'Bodhgaya': ['Kolkatta'],\n",
    "    'Cochin': ['Thiruvanandhapuram'],\n",
    "    'Pushkar': ['Udaipur', 'Ranthambore'],\n",
    "    'Ranthambore': ['Khajuraho'],\n",
    "    'Gir': [],\n",
    "    'Aurangabad': ['Mumbai'],\n",
    "    'Kolkatta': ['Ajanta', 'Bangalore', 'Chennai'],\n",
    "    'Chennai': ['Madurai'],\n",
    "    'Sravasti': ['Kushinagar'],\n",
    "    'Leh': ['Shimla'],\n",
    "    'Sarnath': ['Varanasi'],\n",
    "    'Delhi': ['Jaipur', 'Agra', 'Sravasti'],\n",
    "    'Goa': ['Cochin', 'Bangalore'],\n",
    "    'Kanyakumari': [],\n",
    "    'Kushinagar': ['Sarnath', 'Vaishali'],\n",
    "    'Khajuraho': ['Ajanta'],\n",
    "    'Jaipur': ['Pushkar'],\n",
    "    'Mumbai': ['Goa'],\n",
    "    'Ajanta': ['Ellora', 'Aurangabad']\n",
    "}\n",
    "\n",
    "expected_output = ['Leh', 'Shimla', 'Rishikesh', 'Delhi', 'Sravasti', 'Kushinagar', 'Sarnath', 'Varanasi', 'Bodhgaya', 'Kolkatta',\n",
    "                   'Ajanta', 'Ellora', 'Aurangabad', 'Mumbai', 'Goa', 'Bangalore', 'Chennai', 'Madurai', 'Cochin', 'Thiruvanandhapuram', 'Kanyakumari']\n",
    "\n",
    "long_journey(adjacency_list) == expected_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternate solution, do not prefer 💀\n",
    "\n",
    "1. **DFS for Path Exploration**:\n",
    "    - The `dfs` function uses depth-first search to explore paths starting from a city.\n",
    "    - It marks cities as visited and tracks the longest path found recursively.\n",
    "\n",
    "   1. **Path Exploration**:\n",
    "       - For each unvisited neighboring city, it recursively explores and updates the longest path if a longer path is found.\n",
    "\n",
    "   2. **Backtracking**:\n",
    "       - After exploring all neighbors, it backtracks by removing the city from the path and visited set to explore other paths.\n",
    "\n",
    "2. **Longest Path Calculation**:\n",
    "    - The `long_journey` function iterates through cities, initiating `dfs` from each to find the longest path.\n",
    "    - It records and returns the longest path found across all starting cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs(adjacency_list, city, visited, path):\n",
    "  # mark the current city as visited and add to path\n",
    "  visited[city] = True\n",
    "  path.append(city)\n",
    "  longest_path = list(path)  # track the longest path found\n",
    "\n",
    "  # explore neighbors\n",
    "  for neighbor in adjacency_list[city]:\n",
    "    if not visited[neighbor]:  # if neighbor not visited\n",
    "      current_path = dfs(adjacency_list, neighbor, visited, path)\n",
    "      # update longest_path if current path is longer\n",
    "      if len(current_path) > len(longest_path):\n",
    "        longest_path = current_path\n",
    "\n",
    "  path.pop()  # backtrack: remove current city from path\n",
    "  visited[city] = False  # mark current city as not visited\n",
    "  return longest_path\n",
    "\n",
    "\n",
    "def longest_path(adjacency_list):\n",
    "  longest_path_overall = []  # initialize overall longest path\n",
    "\n",
    "  # find longest path starting from each city\n",
    "  for city in adjacency_list:\n",
    "    visited = {vertex: False for vertex in adjacency_list}  # mark all cities as not visited\n",
    "    current_longest_path = dfs(adjacency_list, city, visited, [])\n",
    "    # update overall longest path if current one is longer\n",
    "    if len(current_longest_path) > len(longest_path_overall):\n",
    "      longest_path_overall = current_longest_path\n",
    "\n",
    "  return longest_path_overall\n",
    "\n",
    "\n",
    "def long_journey(adjacency_list):\n",
    "  # return longest path found\n",
    "  return longest_path(adjacency_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjacency_list = {\n",
    "    'Madurai': ['Cochin', 'Kanyakumari'],\n",
    "    'Vaishali': [],\n",
    "    'Varanasi': ['Khajuraho', 'Bodhgaya'],\n",
    "    'Thiruvanandhapuram': ['Kanyakumari'],\n",
    "    'Udaipur': ['Gir', 'Ajanta'],\n",
    "    'Rishikesh': ['Delhi'],\n",
    "    'Shimla': ['Rishikesh'],\n",
    "    'Bangalore': ['Chennai', 'Madurai'],\n",
    "    'Agra': ['Ranthambore'],\n",
    "    'Ellora': ['Aurangabad'],\n",
    "    'Bodhgaya': ['Kolkatta'],\n",
    "    'Cochin': ['Thiruvanandhapuram'],\n",
    "    'Pushkar': ['Udaipur', 'Ranthambore'],\n",
    "    'Ranthambore': ['Khajuraho'],\n",
    "    'Gir': [],\n",
    "    'Aurangabad': ['Mumbai'],\n",
    "    'Kolkatta': ['Ajanta', 'Bangalore', 'Chennai'],\n",
    "    'Chennai': ['Madurai'],\n",
    "    'Sravasti': ['Kushinagar'],\n",
    "    'Leh': ['Shimla'],\n",
    "    'Sarnath': ['Varanasi'],\n",
    "    'Delhi': ['Jaipur', 'Agra', 'Sravasti'],\n",
    "    'Goa': ['Cochin', 'Bangalore'],\n",
    "    'Kanyakumari': [],\n",
    "    'Kushinagar': ['Sarnath', 'Vaishali'],\n",
    "    'Khajuraho': ['Ajanta'],\n",
    "    'Jaipur': ['Pushkar'],\n",
    "    'Mumbai': ['Goa'],\n",
    "    'Ajanta': ['Ellora', 'Aurangabad']\n",
    "}\n",
    "\n",
    "expected_output = ['Leh', 'Shimla', 'Rishikesh', 'Delhi', 'Sravasti', 'Kushinagar', 'Sarnath', 'Varanasi', 'Bodhgaya', 'Kolkatta',\n",
    "                   'Ajanta', 'Ellora', 'Aurangabad', 'Mumbai', 'Goa', 'Bangalore', 'Chennai', 'Madurai', 'Cochin', 'Thiruvanandhapuram', 'Kanyakumari']\n",
    "\n",
    "long_journey(adjacency_list) == expected_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
